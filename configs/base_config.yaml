# configs/base_config.yaml
# RUN WITH: python -m src.deep_proj.train 
# or without wandb: python -m src.deep_proj.train wandb.enabled=false
wandb:
  enabled: true          # turn off with wandb.enabled=false
  project: deep_vae_karo # CHANGE THIS BEFORE RUNNING
  entity: spicy-mlops    # <- W&B team slug
  group: ${model_name}   # group runs by bottleneck type
  mode: online           # or "offline" / "disabled"

seed: 42

# data (flat keys)
dataset: medmnist            # "mnist" | "medmnist"
data_root: data
batch_size: 100
num_workers: 4
val_split: 0.1
medmnist_subset: organcmnist   # only used if dataset=medmnist

# model (one at a time)
model_name: dirichlet        # gaussian | dirichlet | cc
latent_dim: 10
recon_loss: bce
alpha_init: 0.98            # only used for dirichlet
cc_components: 10           # only used for cc
cc_temperature: 1.0         # only used for cc

# trainer
epochs: 10
lr: 5e-4
device: auto            # "cuda" | "cpu" | "auto"

# early stopping
early_stop_patience: 10      # epochs with no improvement before stopping
early_stop_min_delta: 0.05  # required improvement in val_loss to reset patience

# visualization
viz_every: 5      # or 1 if you want plots every epoch

# checkpoint saving and loading
checkpoint_name: "${dataset}_${model_name}_z${latent_dim}_lr${lr}_best.pt"

hydra:
  run:
    dir: outputs/single/${now:%Y-%m-%d_%H-%M-%S}
  job:
    name: train_vae
