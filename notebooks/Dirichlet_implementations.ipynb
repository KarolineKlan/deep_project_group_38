{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "bPv6dbZCXYCV",
        "outputId": "681708a9-f7d4-492d-8d9f-023fbd1f7e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.94MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.22MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.72MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created with 15784468 trainable parameters\n",
            "Starting training...\n",
            "Configuration: Config(batch_size=256, epochs=10, learning_rate=0.001, no_cuda=False, seed=10, log_interval=2, category=10, alpha=0.3, data_dir='./data', output_dir='./image', encoder_channels=64, decoder_channels=64, input_channels=1, latent_dim=1024, hidden_dim=512)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;31m# Create trainer and start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirVAETrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Applying softmax gives us Dirichlet-distributed variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mdir_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mrecon_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, gauss_z)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;34m\"\"\"Decode latent variables to reconstruction\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2752000808.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, gauss_z)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mdeconv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeconv_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeconv_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeconv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m   1162\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Dirichlet Variational Auto-Encoder (Dir-VAE) implementation for MNIST\n",
        "Based on \"Autoencodeing Variational Inference for Topic Model\" (ICLR2017)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration class for Dir-VAE training\"\"\"\n",
        "\n",
        "    batch_size: int = 256\n",
        "    epochs: int = 10\n",
        "    learning_rate: float = 1e-3\n",
        "    no_cuda: bool = False\n",
        "    seed: int = 10\n",
        "    log_interval: int = 2\n",
        "    category: int = 10  # Number of latent categories (K)\n",
        "    alpha: float = 0.3  # Dirichlet hyperparameter\n",
        "    data_dir: str = \"./data\"\n",
        "    output_dir: str = \"./image\"\n",
        "\n",
        "    # Network architecture parameters\n",
        "    encoder_channels: int = 64\n",
        "    decoder_channels: int = 64\n",
        "    input_channels: int = 1\n",
        "    latent_dim: int = 1024\n",
        "    hidden_dim: int = 512\n",
        "\n",
        "\n",
        "def create_argument_parser() -> argparse.ArgumentParser:\n",
        "    \"\"\"Create and configure argument parser\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Dir-VAE MNIST Example\")\n",
        "    parser.add_argument(\n",
        "        \"--batch-size\",\n",
        "        type=int,\n",
        "        default=256,\n",
        "        metavar=\"N\",\n",
        "        help=\"input batch size for training (default: 256)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--epochs\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"N\",\n",
        "        help=\"number of epochs to train (default: 10)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning-rate\",\n",
        "        type=float,\n",
        "        default=1e-3,\n",
        "        help=\"learning rate (default: 1e-3)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--no-cuda\", action=\"store_true\", default=False, help=\"disable CUDA training\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\", type=int, default=10, metavar=\"S\", help=\"random seed (default: 10)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log-interval\",\n",
        "        type=int,\n",
        "        default=2,\n",
        "        metavar=\"N\",\n",
        "        help=\"how many batches to wait before logging training status\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--category\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"K\",\n",
        "        help=\"the number of categories in the dataset\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--alpha\",\n",
        "        type=float,\n",
        "        default=0.3,\n",
        "        help=\"Dirichlet hyperparameter alpha (default: 0.3)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--data-dir\",\n",
        "        type=str,\n",
        "        default=\"./data\",\n",
        "        help=\"directory for dataset (default: ./data)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-dir\",\n",
        "        type=str,\n",
        "        default=\"./image\",\n",
        "        help=\"directory for output images (default: ./image)\",\n",
        "    )\n",
        "    return parser\n",
        "\n",
        "\n",
        "def setup_device_and_seed(config: Config) -> torch.device:\n",
        "    \"\"\"Setup device and random seeds\"\"\"\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(config.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config.seed)\n",
        "\n",
        "    # Determine device\n",
        "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "\n",
        "def create_data_loaders(\n",
        "    config: Config,\n",
        ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
        "    \"\"\"Create train and test data loaders\"\"\"\n",
        "    # Create data directory if it doesn't exist\n",
        "    os.makedirs(config.data_dir, exist_ok=True)\n",
        "\n",
        "    # Data loader kwargs\n",
        "    kwargs = (\n",
        "        {\"num_workers\": 1, \"pin_memory\": True}\n",
        "        if not config.no_cuda and torch.cuda.is_available()\n",
        "        else {}\n",
        "    )\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            config.data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
        "        ),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(config.data_dir, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def compute_dirichlet_prior(\n",
        "    K: int, alpha: float, device: torch.device\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Compute Dirichlet prior parameters using Laplace approximation.\n",
        "\n",
        "    Args:\n",
        "        K: Number of categories\n",
        "        alpha: Dirichlet hyperparameter\n",
        "        device: torch device\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (mean, variance) tensors for the approximated normal distribution\n",
        "    \"\"\"\n",
        "    # Laplace approximation to convert Dirichlet to multivariate normal\n",
        "    a = torch.full((1, K), alpha, dtype=torch.float, device=device)\n",
        "    mean = a.log().t() - a.log().mean(1, keepdim=True)\n",
        "    var = ((1 - 2.0 / K) * a.reciprocal()).t() + (1.0 / K**2) * a.reciprocal().sum(\n",
        "        1, keepdim=True\n",
        "    )\n",
        "    return mean.t(), var.t()\n",
        "\n",
        "\n",
        "class DirVAEEncoder(nn.Module):\n",
        "    \"\"\"Encoder part of Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(DirVAEEncoder, self).__init__()\n",
        "        ndf = config.encoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # input: (nc) x 28 x 28\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf) x 14 x 14\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*2) x 7 x 7\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, config.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(config.latent_dim, config.hidden_dim)\n",
        "        self.fc_mu = nn.Linear(config.hidden_dim, config.category)\n",
        "        self.fc_logvar = nn.Linear(config.hidden_dim, config.category)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        conv_out = self.conv_layers(x)\n",
        "        h1 = self.fc1(conv_out.view(conv_out.size(0), -1))\n",
        "        mu = self.fc_mu(h1)\n",
        "        logvar = self.fc_logvar(h1)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class DirVAEDecoder(nn.Module):\n",
        "    \"\"\"Decoder part of Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(DirVAEDecoder, self).__init__()\n",
        "        ngf = config.decoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.fc_decode = nn.Linear(config.category, config.hidden_dim)\n",
        "        self.fc_deconv = nn.Linear(config.hidden_dim, config.latent_dim)\n",
        "\n",
        "        self.deconv_layers = nn.Sequential(\n",
        "            # input: latent_dim x 1 x 1\n",
        "            nn.ConvTranspose2d(config.latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "            # output: (nc) x 32 x 32\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, gauss_z: torch.Tensor) -> torch.Tensor:\n",
        "        # Apply softmax to satisfy simplex constraint (Dirichlet distribution)\n",
        "        dir_z = F.softmax(gauss_z, dim=1)\n",
        "\n",
        "        h3 = self.relu(self.fc_decode(dir_z))\n",
        "        deconv_input = self.fc_deconv(h3)\n",
        "        deconv_input = deconv_input.view(-1, deconv_input.size(1), 1, 1)\n",
        "\n",
        "        return self.deconv_layers(deconv_input)\n",
        "\n",
        "\n",
        "class DirVAE(nn.Module):\n",
        "    \"\"\"Dirichlet Variational Auto-Encoder\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config, device: torch.device):\n",
        "        super(DirVAE, self).__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize encoder and decoder\n",
        "        self.encoder = DirVAEEncoder(config)\n",
        "        self.decoder = DirVAEDecoder(config)\n",
        "\n",
        "        # Setup Dirichlet prior\n",
        "        self._setup_dirichlet_prior()\n",
        "\n",
        "    def _setup_dirichlet_prior(self):\n",
        "        \"\"\"Setup Dirichlet prior parameters\"\"\"\n",
        "        prior_mean, prior_var = compute_dirichlet_prior(\n",
        "            self.config.category, self.config.alpha, self.device\n",
        "        )\n",
        "        self.register_buffer(\"prior_mean\", prior_mean)\n",
        "        self.register_buffer(\"prior_var\", prior_var)\n",
        "        self.register_buffer(\"prior_logvar\", prior_var.log())\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Encode input to latent parameters\"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, gauss_z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decode latent variables to reconstruction\"\"\"\n",
        "        return self.decoder(gauss_z)\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Reparameterization trick for backpropagation through stochastic nodes\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass through the network\"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        gauss_z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # gauss_z follows multivariate normal distribution\n",
        "        # Applying softmax gives us Dirichlet-distributed variables\n",
        "        dir_z = F.softmax(gauss_z, dim=1)\n",
        "        recon_x = self.decode(gauss_z)\n",
        "\n",
        "        return recon_x, mu, logvar, gauss_z, dir_z\n",
        "\n",
        "    def loss_function(\n",
        "        self,\n",
        "        recon_x: torch.Tensor,\n",
        "        x: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the loss function: reconstruction loss + KL divergence\n",
        "\n",
        "        Args:\n",
        "            recon_x: Reconstructed images\n",
        "            x: Original images\n",
        "            mu: Mean of latent distribution\n",
        "            logvar: Log variance of latent distribution\n",
        "\n",
        "        Returns:\n",
        "            Total loss (sum over batch)\n",
        "        \"\"\"\n",
        "        # Reconstruction loss (Binary Cross Entropy)\n",
        "        BCE = F.binary_cross_entropy(\n",
        "            recon_x.view(-1, 784), x.view(-1, 784), reduction=\"sum\"\n",
        "        )\n",
        "\n",
        "        # KL divergence between Dirichlet prior and variational posterior\n",
        "        # Based on the original paper: \"Autoencodeing variational inference for topic model\"\n",
        "        prior_mean = self.prior_mean.expand_as(mu)\n",
        "        prior_var = self.prior_var.expand_as(logvar)\n",
        "        prior_logvar = self.prior_logvar.expand_as(logvar)\n",
        "\n",
        "        var_division = logvar.exp() / prior_var  # Σ_0 / Σ_1\n",
        "        diff = mu - prior_mean  # μ_1 - μ_0\n",
        "        diff_term = diff * diff / prior_var  # (μ_1 - μ_0)² / Σ_1\n",
        "        logvar_division = prior_logvar - logvar  # log|Σ_1| - log|Σ_0|\n",
        "\n",
        "        # KL divergence\n",
        "        KLD = 0.5 * (\n",
        "            var_division + diff_term + logvar_division - self.config.category\n",
        "        ).sum(dim=1)\n",
        "\n",
        "        return BCE + KLD.sum()\n",
        "\n",
        "\n",
        "class DirVAETrainer:\n",
        "    \"\"\"Trainer class for Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: DirVAE,\n",
        "        config: Config,\n",
        "        device: torch.device,\n",
        "        train_loader: torch.utils.data.DataLoader,\n",
        "        test_loader: torch.utils.data.DataLoader,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        # Initialize optimizer\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    def train_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_idx, (data, _) in enumerate(self.train_loader):\n",
        "            data = data.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar, gauss_z, dir_z = self.model(data)\n",
        "            loss = self.model.loss_function(recon_batch, data, mu, logvar)\n",
        "\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if batch_idx % self.config.log_interval == 0:\n",
        "                print(\n",
        "                    f\"Train Epoch: {epoch} [{batch_idx * len(data):5d}/\"\n",
        "                    f\"{len(self.train_loader.dataset)} \"\n",
        "                    f\"({100. * batch_idx / len(self.train_loader):3.0f}%)]\"\n",
        "                    f\"\\tLoss: {loss.item() / len(data):.6f}\"\n",
        "                )\n",
        "\n",
        "        avg_loss = train_loss / len(self.train_loader.dataset)\n",
        "        print(f\"====> Epoch: {epoch} Average loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def test_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Test for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (data, _) in enumerate(self.test_loader):\n",
        "                data = data.to(self.device)\n",
        "                recon_batch, mu, logvar, gauss_z, dir_z = self.model(data)\n",
        "                loss = self.model.loss_function(recon_batch, data, mu, logvar)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                if i == 0:\n",
        "                    n = min(data.size(0), 18)\n",
        "                    # Properly reshape for comparison\n",
        "                    comparison = torch.cat(\n",
        "                        [data[:n], recon_batch.view(data.size(0), 1, 28, 28)[:n]]\n",
        "                    )\n",
        "                    save_image(\n",
        "                        comparison.cpu(),\n",
        "                        os.path.join(self.config.output_dir, f\"recon_{epoch}.png\"),\n",
        "                        nrow=n,\n",
        "                    )\n",
        "\n",
        "        avg_loss = test_loss / len(self.test_loader.dataset)\n",
        "        print(f\"====> Test set loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def generate_samples(self, epoch: int, num_samples: int = 64):\n",
        "        \"\"\"Generate samples from the model\"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Sample from latent space\n",
        "            sample = torch.randn(num_samples, self.config.category).to(self.device)\n",
        "            sample = self.model.decode(sample).cpu()\n",
        "            save_image(\n",
        "                sample.view(num_samples, 1, 28, 28),\n",
        "                os.path.join(self.config.output_dir, f\"sample_{epoch}.png\"),\n",
        "            )\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(\"Starting training...\")\n",
        "        print(f\"Configuration: {self.config}\")\n",
        "\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            train_loss = self.train_epoch(epoch)\n",
        "            test_loss = self.test_epoch(epoch)\n",
        "            self.generate_samples(epoch)\n",
        "\n",
        "\n",
        "\"\"\"Main function\"\"\"\n",
        "# Parse arguments\n",
        "parser = create_argument_parser()\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "# Create configuration\n",
        "config = Config(\n",
        "    batch_size=args.batch_size,\n",
        "    epochs=args.epochs,\n",
        "    learning_rate=args.learning_rate,\n",
        "    no_cuda=args.no_cuda,\n",
        "    seed=args.seed,\n",
        "    log_interval=args.log_interval,\n",
        "    category=args.category,\n",
        "    alpha=args.alpha,\n",
        "    data_dir=args.data_dir,\n",
        "    output_dir=args.output_dir,\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Setup device and random seeds\n",
        "    device = setup_device_and_seed(config)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader, test_loader = create_data_loaders(config)\n",
        "\n",
        "    # Create model\n",
        "    model = DirVAE(config, device).to(device)\n",
        "    print(\n",
        "        f\"Model created with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\"\n",
        "    )\n",
        "\n",
        "    # Create trainer and start training\n",
        "    trainer = DirVAETrainer(model, config, device, train_loader, test_loader)\n",
        "    trainer.train()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\", file=sys.stderr)\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Gauss try (doesnt work yet)\n",
        "\n",
        "\"\"\"\n",
        "Gauss Variational Auto-Encoder (Gauss-VAE) implementation for MNIST\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration class for Gauss-VAE training\"\"\"\n",
        "\n",
        "    batch_size: int = 256\n",
        "    epochs: int = 10\n",
        "    learning_rate: float = 1e-3\n",
        "    no_cuda: bool = False\n",
        "    seed: int = 10\n",
        "    log_interval: int = 2\n",
        "    category: int = 10  # Number of latent categories (K)\n",
        "    data_dir: str = \"./data\"\n",
        "    output_dir: str = \"./image\"\n",
        "\n",
        "    # Network architecture parameters\n",
        "    encoder_channels: int = 64\n",
        "    decoder_channels: int = 64\n",
        "    input_channels: int = 1\n",
        "    latent_dim: int = 1024\n",
        "    hidden_dim: int = 512\n",
        "\n",
        "\n",
        "def create_argument_parser() -> argparse.ArgumentParser:\n",
        "    \"\"\"Create and configure argument parser\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Gauss-VAE MNIST Example\")\n",
        "    parser.add_argument(\n",
        "        \"--batch-size\",\n",
        "        type=int,\n",
        "        default=256,\n",
        "        metavar=\"N\",\n",
        "        help=\"input batch size for training (default: 256)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--epochs\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"N\",\n",
        "        help=\"number of epochs to train (default: 10)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning-rate\",\n",
        "        type=float,\n",
        "        default=1e-3,\n",
        "        help=\"learning rate (default: 1e-3)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--no-cuda\", action=\"store_true\", default=False, help=\"disable CUDA training\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\", type=int, default=10, metavar=\"S\", help=\"random seed (default: 10)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log-interval\",\n",
        "        type=int,\n",
        "        default=2,\n",
        "        metavar=\"N\",\n",
        "        help=\"how many batches to wait before logging training status\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--category\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"K\",\n",
        "        help=\"the number of categories in the dataset\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--data-dir\",\n",
        "        type=str,\n",
        "        default=\"./data\",\n",
        "        help=\"directory for dataset (default: ./data)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-dir\",\n",
        "        type=str,\n",
        "        default=\"./image\",\n",
        "        help=\"directory for output images (default: ./image)\",\n",
        "    )\n",
        "    return parser\n",
        "\n",
        "\n",
        "def setup_device_and_seed(config: Config) -> torch.device:\n",
        "    \"\"\"Setup device and random seeds\"\"\"\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(config.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config.seed)\n",
        "\n",
        "    # Determine device\n",
        "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "\n",
        "def create_data_loaders(\n",
        "    config: Config,\n",
        ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
        "    \"\"\"Create train and test data loaders\"\"\"\n",
        "    # Create data directory if it doesn't exist\n",
        "    os.makedirs(config.data_dir, exist_ok=True)\n",
        "\n",
        "    # Data loader kwargs\n",
        "    kwargs = (\n",
        "        {\"num_workers\": 1, \"pin_memory\": True}\n",
        "        if not config.no_cuda and torch.cuda.is_available()\n",
        "        else {}\n",
        "    )\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            config.data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
        "        ),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(config.data_dir, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "class GaussVAEEncoder(nn.Module):\n",
        "    \"\"\"Encoder part of Gauss-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(GaussVAEEncoder, self).__init__()\n",
        "        ndf = config.encoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # input: (nc) x 28 x 28\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf) x 14 x 14\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*2) x 7 x 7\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, config.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(config.latent_dim, config.hidden_dim)\n",
        "        self.fc_mu = nn.Linear(config.hidden_dim, config.category)\n",
        "        self.fc_logvar = nn.Linear(config.hidden_dim, config.category)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        conv_out = self.conv_layers(x)\n",
        "        h1 = self.fc1(conv_out.view(conv_out.size(0), -1))\n",
        "        mu = self.fc_mu(h1)\n",
        "        logvar = self.fc_logvar(h1)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class GaussVAEDecoder(nn.Module):\n",
        "    \"\"\"Decoder part of Gauss-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(GaussVAEDecoder, self).__init__()\n",
        "        ngf = config.decoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.fc_decode = nn.Linear(config.category, config.hidden_dim)\n",
        "        self.fc_deconv = nn.Linear(config.hidden_dim, config.latent_dim)\n",
        "\n",
        "        self.deconv_layers = nn.Sequential(\n",
        "            # input: latent_dim x 1 x 1\n",
        "            nn.ConvTranspose2d(config.latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "            # output: (nc) x 32 x 32\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, gauss_z: torch.Tensor) -> torch.Tensor:\n",
        "        h3 = self.relu(self.fc_decode(gauss_z))\n",
        "        deconv_input = self.fc_deconv(h3)\n",
        "        deconv_input = deconv_input.view(-1, deconv_input.size(1), 1, 1)\n",
        "\n",
        "        return self.deconv_layers(deconv_input)\n",
        "\n",
        "\n",
        "class GaussVAE(nn.Module):\n",
        "    \"\"\"Gauss Variational Auto-Encoder\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config, device: torch.device):\n",
        "        super(GaussVAE, self).__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize encoder and decoder\n",
        "        self.encoder = GaussVAEEncoder(config)\n",
        "        self.decoder = GaussVAEDecoder(config)\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Encode input to latent parameters\"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, gauss_z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decode latent variables to reconstruction\"\"\"\n",
        "        return self.decoder(gauss_z)\n",
        "\n",
        "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Reparameterization trick for backpropagation through stochastic nodes\"\"\"\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass through the network\"\"\"\n",
        "        mu, logvar = self.encode(x)\n",
        "        gauss_z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(gauss_z)\n",
        "\n",
        "        return recon_x, mu, logvar, gauss_z\n",
        "\n",
        "    def loss_function(\n",
        "        self,\n",
        "        recon_x: torch.Tensor,\n",
        "        x: torch.Tensor,\n",
        "        mu: torch.Tensor,\n",
        "        logvar: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the loss function: reconstruction loss + KL divergence\n",
        "\n",
        "        Args:\n",
        "            recon_x: Reconstructed images\n",
        "            x: Original images\n",
        "            mu: Mean of latent distribution\n",
        "            logvar: Log variance of latent distribution\n",
        "\n",
        "        Returns:\n",
        "            Total loss (sum over batch)\n",
        "        \"\"\"\n",
        "        # Reconstruction loss (Binary Cross Entropy)\n",
        "        BCE = F.binary_cross_entropy(\n",
        "            recon_x.view(-1, 784), x.view(-1, 784), reduction=\"sum\"\n",
        "        )\n",
        "\n",
        "\n",
        "        # KL divergence\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "        return BCE + KLD\n",
        "\n",
        "\n",
        "class GaussVAETrainer:\n",
        "    \"\"\"Trainer class for Gauss-VAE\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: GaussVAE,\n",
        "        config: Config,\n",
        "        device: torch.device,\n",
        "        train_loader: torch.utils.data.DataLoader,\n",
        "        test_loader: torch.utils.data.DataLoader,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        # Initialize optimizer\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    def train_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_idx, (data, _) in enumerate(self.train_loader):\n",
        "            data = data.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar, gauss_z= self.model(data)\n",
        "            loss = self.model.loss_function(recon_batch, data, mu, logvar)\n",
        "\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if batch_idx % self.config.log_interval == 0:\n",
        "                print(\n",
        "                    f\"Train Epoch: {epoch} [{batch_idx * len(data):5d}/\"\n",
        "                    f\"{len(self.train_loader.dataset)} \"\n",
        "                    f\"({100. * batch_idx / len(self.train_loader):3.0f}%)]\"\n",
        "                    f\"\\tLoss: {loss.item() / len(data):.6f}\"\n",
        "                )\n",
        "\n",
        "        avg_loss = train_loss / len(self.train_loader.dataset)\n",
        "        print(f\"====> Epoch: {epoch} Average loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def test_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Test for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (data, _) in enumerate(self.test_loader):\n",
        "                data = data.to(self.device)\n",
        "                recon_batch, mu, logvar, gauss_z = self.model(data)\n",
        "                loss = self.model.loss_function(recon_batch, data, mu, logvar)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                if i == 0:\n",
        "                    n = min(data.size(0), 18)\n",
        "                    # Properly reshape for comparison\n",
        "                    comparison = torch.cat(\n",
        "                        [data[:n], recon_batch.view(data.size(0), 1, 28, 28)[:n]]\n",
        "                    )\n",
        "                    save_image(\n",
        "                        comparison.cpu(),\n",
        "                        os.path.join(self.config.output_dir, f\"recon_{epoch}.png\"),\n",
        "                        nrow=n,\n",
        "                    )\n",
        "\n",
        "        avg_loss = test_loss / len(self.test_loader.dataset)\n",
        "        print(f\"====> Test set loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def generate_samples(self, epoch: int, num_samples: int = 64):\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        # sample from standard Gaussian prior\n",
        "        z = torch.randn(num_samples, self.config.latent_dim, device=self.device)\n",
        "        sample = self.model.decode(z).cpu()\n",
        "        save_image(\n",
        "            sample.view(num_samples, 1, 28, 28),\n",
        "            os.path.join(self.config.output_dir, f\"sample_{epoch}.png\"),\n",
        "            nrow=8\n",
        "        )\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(\"Starting training...\")\n",
        "        print(f\"Configuration: {self.config}\")\n",
        "\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            train_loss = self.train_epoch(epoch)\n",
        "            test_loss = self.test_epoch(epoch)\n",
        "            self.generate_samples(epoch)\n",
        "\n",
        "\n",
        "def main(argv=None):\n",
        "    parser = create_argument_parser()\n",
        "\n",
        "    # When running in notebook, argv should be empty to use defaults.\n",
        "    if argv is None:\n",
        "        # Detect running in IPython/Jupyter and avoid taking notebook argv\n",
        "        if \"ipykernel\" in sys.modules:\n",
        "            args = parser.parse_args([])\n",
        "        else:\n",
        "            args = parser.parse_args()\n",
        "    else:\n",
        "        args = parser.parse_args(argv)\n",
        "\n",
        "    config = Config(\n",
        "        batch_size=args.batch_size,\n",
        "        epochs=args.epochs,\n",
        "        learning_rate=args.learning_rate,\n",
        "        no_cuda=args.no_cuda,\n",
        "        seed=args.seed,\n",
        "        log_interval=args.log_interval,\n",
        "        category=args.category,\n",
        "        data_dir=args.data_dir,\n",
        "        output_dir=args.output_dir,\n",
        "    )\n",
        "\n",
        "    device = setup_device_and_seed(config)\n",
        "    train_loader, test_loader = create_data_loaders(config)\n",
        "\n",
        "    model = GaussVAE(config, device).to(device)\n",
        "    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Model created with {n_params} trainable parameters\")\n",
        "\n",
        "    trainer = GaussVAETrainer(model, config, device, train_loader, test_loader)\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqaqSUb7YyAK",
        "outputId": "2675e9d1-a018-4dd1-d022-3917ea5c6c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model created with 15784468 trainable parameters\n",
            "Starting training...\n",
            "Configuration: Config(batch_size=256, epochs=10, learning_rate=0.001, no_cuda=False, seed=10, log_interval=2, category=10, data_dir='./data', output_dir='./image', encoder_channels=64, decoder_channels=64, input_channels=1, latent_dim=1024, hidden_dim=512)\n",
            "Train Epoch: 1 [    0/60000 (  0%)]\tLoss: 664.023376\n",
            "Train Epoch: 1 [  512/60000 (  1%)]\tLoss: 1024.685303\n",
            "Train Epoch: 1 [ 1024/60000 (  2%)]\tLoss: 387.771484\n",
            "Train Epoch: 1 [ 1536/60000 (  3%)]\tLoss: 277.235809\n",
            "Train Epoch: 1 [ 2048/60000 (  3%)]\tLoss: 259.702667\n",
            "Train Epoch: 1 [ 2560/60000 (  4%)]\tLoss: 240.780960\n",
            "Train Epoch: 1 [ 3072/60000 (  5%)]\tLoss: 236.565521\n",
            "Train Epoch: 1 [ 3584/60000 (  6%)]\tLoss: 226.450684\n",
            "Train Epoch: 1 [ 4096/60000 (  7%)]\tLoss: 227.766541\n",
            "Train Epoch: 1 [ 4608/60000 (  8%)]\tLoss: 213.367126\n",
            "Train Epoch: 1 [ 5120/60000 (  9%)]\tLoss: 211.869003\n",
            "Train Epoch: 1 [ 5632/60000 (  9%)]\tLoss: 208.035919\n",
            "Train Epoch: 1 [ 6144/60000 ( 10%)]\tLoss: 212.186783\n",
            "Train Epoch: 1 [ 6656/60000 ( 11%)]\tLoss: 207.046753\n",
            "Train Epoch: 1 [ 7168/60000 ( 12%)]\tLoss: 199.860352\n",
            "Train Epoch: 1 [ 7680/60000 ( 13%)]\tLoss: 202.235535\n",
            "Train Epoch: 1 [ 8192/60000 ( 14%)]\tLoss: 206.863174\n",
            "Train Epoch: 1 [ 8704/60000 ( 14%)]\tLoss: 201.291656\n",
            "Train Epoch: 1 [ 9216/60000 ( 15%)]\tLoss: 203.741608\n",
            "Train Epoch: 1 [ 9728/60000 ( 16%)]\tLoss: 198.589096\n",
            "Train Epoch: 1 [10240/60000 ( 17%)]\tLoss: 202.989899\n",
            "Train Epoch: 1 [10752/60000 ( 18%)]\tLoss: 202.083633\n",
            "Train Epoch: 1 [11264/60000 ( 19%)]\tLoss: 198.783524\n",
            "Train Epoch: 1 [11776/60000 ( 20%)]\tLoss: 197.298279\n",
            "Train Epoch: 1 [12288/60000 ( 20%)]\tLoss: 196.004288\n",
            "Train Epoch: 1 [12800/60000 ( 21%)]\tLoss: 196.221893\n",
            "Train Epoch: 1 [13312/60000 ( 22%)]\tLoss: 198.466995\n",
            "Train Epoch: 1 [13824/60000 ( 23%)]\tLoss: 194.781418\n",
            "Train Epoch: 1 [14336/60000 ( 24%)]\tLoss: 192.966660\n",
            "Train Epoch: 1 [14848/60000 ( 25%)]\tLoss: 192.227982\n",
            "Train Epoch: 1 [15360/60000 ( 26%)]\tLoss: 195.970978\n",
            "Train Epoch: 1 [15872/60000 ( 26%)]\tLoss: 192.829437\n",
            "Train Epoch: 1 [16384/60000 ( 27%)]\tLoss: 188.759094\n",
            "Train Epoch: 1 [16896/60000 ( 28%)]\tLoss: 195.433853\n",
            "Train Epoch: 1 [17408/60000 ( 29%)]\tLoss: 193.483749\n",
            "Train Epoch: 1 [17920/60000 ( 30%)]\tLoss: 188.734756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Forsøg på DIR fra den nye artikel\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "EPS = 1e-8\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration class for Dir-VAE training\"\"\"\n",
        "\n",
        "    batch_size: int = 256\n",
        "    epochs: int = 10\n",
        "    learning_rate: float = 1e-3\n",
        "    no_cuda: bool = False\n",
        "    seed: int = 10\n",
        "    log_interval: int = 2\n",
        "    category: int = 10  # Number of latent categories (K)\n",
        "    alpha: float = 0.3  # Dirichlet hyperparameter\n",
        "    data_dir: str = \"./data\"\n",
        "    output_dir: str = \"./image\"\n",
        "    beta=1.0\n",
        "\n",
        "    # Network architecture parameters\n",
        "    encoder_channels: int = 64\n",
        "    decoder_channels: int = 64\n",
        "    input_channels: int = 1\n",
        "    latent_dim: int = 1024\n",
        "    hidden_dim: int = 512\n",
        "\n",
        "\n",
        "def create_argument_parser() -> argparse.ArgumentParser:\n",
        "    \"\"\"Create and configure argument parser\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Dir-VAE MNIST Example\")\n",
        "    parser.add_argument(\n",
        "        \"--batch-size\",\n",
        "        type=int,\n",
        "        default=256,\n",
        "        metavar=\"N\",\n",
        "        help=\"input batch size for training (default: 256)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--epochs\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"N\",\n",
        "        help=\"number of epochs to train (default: 10)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning-rate\",\n",
        "        type=float,\n",
        "        default=1e-3,\n",
        "        help=\"learning rate (default: 1e-3)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--no-cuda\", action=\"store_true\", default=False, help=\"disable CUDA training\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--seed\", type=int, default=10, metavar=\"S\", help=\"random seed (default: 10)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--log-interval\",\n",
        "        type=int,\n",
        "        default=2,\n",
        "        metavar=\"N\",\n",
        "        help=\"how many batches to wait before logging training status\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--category\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        metavar=\"K\",\n",
        "        help=\"the number of categories in the dataset\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--alpha\",\n",
        "        type=float,\n",
        "        default=0.3,\n",
        "        help=\"Dirichlet hyperparameter alpha (default: 0.3)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--data-dir\",\n",
        "        type=str,\n",
        "        default=\"./data\",\n",
        "        help=\"directory for dataset (default: ./data)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-dir\",\n",
        "        type=str,\n",
        "        default=\"./image\",\n",
        "        help=\"directory for output images (default: ./image)\",\n",
        "    )\n",
        "    return parser\n",
        "\n",
        "\n",
        "def setup_device_and_seed(config: Config) -> torch.device:\n",
        "    \"\"\"Setup device and random seeds\"\"\"\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(config.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(config.seed)\n",
        "\n",
        "    # Determine device\n",
        "    use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "\n",
        "def create_data_loaders(\n",
        "    config: Config,\n",
        ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
        "    \"\"\"Create train and test data loaders\"\"\"\n",
        "    # Create data directory if it doesn't exist\n",
        "    os.makedirs(config.data_dir, exist_ok=True)\n",
        "\n",
        "    # Data loader kwargs\n",
        "    kwargs = (\n",
        "        {\"num_workers\": 1, \"pin_memory\": True}\n",
        "        if not config.no_cuda and torch.cuda.is_available()\n",
        "        else {}\n",
        "    )\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(\n",
        "            config.data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
        "        ),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(config.data_dir, train=False, transform=transforms.ToTensor()),\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        **kwargs,\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def compute_dirichlet_prior(\n",
        "    K: int, alpha: float, device: torch.device\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Compute Dirichlet prior parameters using Laplace approximation.\n",
        "\n",
        "    Args:\n",
        "        K: Number of categories\n",
        "        alpha: Dirichlet hyperparameter\n",
        "        device: torch device\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (mean, variance) tensors for the approximated normal distribution\n",
        "    \"\"\"\n",
        "    # Laplace approximation to convert Dirichlet to multivariate normal\n",
        "    a = torch.full((1, K), alpha, dtype=torch.float, device=device)\n",
        "    mean = a.log().t() - a.log().mean(1, keepdim=True)\n",
        "    var = ((1 - 2.0 / K) * a.reciprocal()).t() + (1.0 / K**2) * a.reciprocal().sum(\n",
        "        1, keepdim=True\n",
        "    )\n",
        "    return mean.t(), var.t()\n",
        "\n",
        "\n",
        "class DirVAEEncoder(nn.Module):\n",
        "    \"\"\"Encoder part of Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(DirVAEEncoder, self).__init__()\n",
        "        ndf = config.encoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # input: (nc) x 28 x 28\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf) x 14 x 14\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*2) x 7 x 7\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state: (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, config.latent_dim, 4, 1, 0, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(config.latent_dim, config.hidden_dim)\n",
        "        self.fc_mu = nn.Linear(config.hidden_dim, config.category)\n",
        "        self.fc_logvar = nn.Linear(config.hidden_dim, config.category)\n",
        "        self.softplus = nn.Softplus()\n",
        "        self.fc_alpha = nn.Linear(config.hidden_dim, config.category)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        conv_out = self.conv_layers(x)\n",
        "\n",
        "        h1 = self.fc1(conv_out.view(conv_out.size(0), -1))\n",
        "        alpha_hat=self.softplus(self.fc_alpha(h1))\n",
        "        return alpha_hat\n",
        "\n",
        "\n",
        "class DirVAEDecoder(nn.Module):\n",
        "    \"\"\"Decoder part of Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super(DirVAEDecoder, self).__init__()\n",
        "        ngf = config.decoder_channels\n",
        "        nc = config.input_channels\n",
        "\n",
        "        self.fc_decode = nn.Linear(config.category, config.hidden_dim)\n",
        "        self.fc_deconv = nn.Linear(config.hidden_dim, config.latent_dim)\n",
        "\n",
        "        self.deconv_layers = nn.Sequential(\n",
        "            # input: latent_dim x 1 x 1\n",
        "            nn.ConvTranspose2d(config.latent_dim, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state: (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "            # output: (nc) x 32 x 32\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        # Apply softmax to satisfy simplex constraint (Dirichlet distribution)\n",
        "\n",
        "        h3 = self.fc_decode(z)\n",
        "        deconv_input = self.fc_deconv(h3)\n",
        "        deconv_input = deconv_input.view(-1, deconv_input.size(1), 1, 1)\n",
        "\n",
        "        return self.deconv_layers(deconv_input)\n",
        "\n",
        "\n",
        "class DirVAE(nn.Module):\n",
        "    \"\"\"Dirichlet Variational Auto-Encoder\"\"\"\n",
        "\n",
        "    def __init__(self, config: Config, device: torch.device):\n",
        "        super(DirVAE, self).__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize encoder and decoder\n",
        "        self.encoder = DirVAEEncoder(config)\n",
        "        self.decoder = DirVAEDecoder(config)\n",
        "        # Initialize prior_alpha\n",
        "        if not hasattr(config, \"prior_alpha\") or config.alpha is None:\n",
        "            # default weak symmetric prior\n",
        "            prior_alpha = torch.ones(config.category) * 0.98\n",
        "        else:\n",
        "            # use config.alpha (scalar or tensor)\n",
        "            prior_alpha = torch.tensor(config.alpha).repeat(config.category)\n",
        "\n",
        "        self.register_buffer('prior_alpha', prior_alpha.float())\n",
        "        self.register_buffer('beta', torch.tensor(float(config.beta)))\n",
        "\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Encode input to latent parameters\"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Decode latent variables to reconstruction\"\"\"\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def inverse_gamma_cdf_approx(self, u, alpha):\n",
        "        \"\"\"\n",
        "        Approximate inverse CDF for X ~ Gamma(alpha, beta) using:\n",
        "        F^{-1}(u; alpha, beta) ≈ beta^{-1} * (u * alpha * Gamma(alpha))^{1/alpha}\n",
        "        u: uniform samples in (0,1), shape (batch, K)\n",
        "        alpha: shape (batch, K) or (K,)\n",
        "        returns: approx gamma samples shape (batch, K)\n",
        "        \"\"\"\n",
        "        # alpha * Gamma(alpha) = alpha * exp(lgamma(alpha))\n",
        "        # note: torch.lgamma for log Gamma\n",
        "        # shapes broadcast\n",
        "        log_gamma = torch.lgamma(alpha)\n",
        "        a_gamma = alpha * torch.exp(log_gamma)  # shape (batch, K)\n",
        "        # clamp u to (eps, 1)\n",
        "        u = u.clamp(min=EPS, max=1.0 - 1e-12)\n",
        "        base = u * a_gamma\n",
        "        # to avoid negative/zero values due to numerical issues, clamp base\n",
        "        base = base.clamp(min=EPS)\n",
        "        # power 1/alpha\n",
        "        samples = (base) ** (1.0 / alpha)\n",
        "        # divide by beta (rate)\n",
        "        samples = samples / (self.beta + 0.0)\n",
        "        return samples\n",
        "\n",
        "    def sample_dirichlet_from_alpha(self, alpha_hat):\n",
        "        \"\"\"\n",
        "        Given alpha_hat (batch, K), produce reparam samples z on simplex:\n",
        "          1) draw u ~ Uniform(0,1) per component\n",
        "          2) approximate gamma sample via inverse Gamma CDF approx\n",
        "          3) normalize v -> z = v / sum_k v_k\n",
        "        Returns z (batch, K), v (batch, K), u (for reproducibility)\n",
        "        \"\"\"\n",
        "        assert torch.all(alpha_hat > 0), \"alpha_hat must be positive\"\n",
        "        batch = alpha_hat.shape[0]\n",
        "        # Uniform draws per component\n",
        "        u = torch.rand_like(alpha_hat)  # Uniform(0,1)\n",
        "        v = self.inverse_gamma_cdf_approx(u, alpha_hat)\n",
        "        # Normalize to get Dirichlet sample\n",
        "        denom = v.sum(dim=1, keepdim=True).clamp(min=EPS)\n",
        "        z = v / denom\n",
        "        return z, v, u\n",
        "\n",
        "    def forward(\n",
        "        self, x: torch.Tensor\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Forward pass through the network\"\"\"\n",
        "        alpha_hat = self.encode(x)\n",
        "        z, v, u = self.sample_dirichlet_from_alpha(alpha_hat)\n",
        "        recon_x = self.decode(z)\n",
        "\n",
        "        return recon_x, z,alpha_hat,v\n",
        "\n",
        "    def loss_function(\n",
        "        self,\n",
        "        recon_x: torch.Tensor,\n",
        "        x: torch.Tensor,\n",
        "        alpha_hat: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the loss function: reconstruction loss + KL divergence\n",
        "\n",
        "        Args:\n",
        "            recon_x: Reconstructed images\n",
        "            x: Original images\n",
        "            mu: Mean of latent distribution\n",
        "            logvar: Log variance of latent distribution\n",
        "\n",
        "        Returns:\n",
        "            Total loss (sum over batch)\n",
        "        \"\"\"\n",
        "        # Reconstruction loss (Binary Cross Entropy)\n",
        "        recon_x = recon_x.clamp(0.0, 1.0)\n",
        "        BCE = F.binary_cross_entropy(\n",
        "            recon_x.view(-1, self.cfg.input_dim),\n",
        "            x.view(-1, self.cfg.input_dim),\n",
        "            reduction=\"sum\"\n",
        "        )\n",
        "\n",
        "\n",
        "        # KL divergence\n",
        "        # broadcast prior_alpha to batch if necessary\n",
        "        if self.prior_alpha.dim() == 1:\n",
        "            prior = self.prior_alpha.unsqueeze(0).expand_as(alpha_hat)\n",
        "        else:\n",
        "            prior = self.prior_alpha\n",
        "        term1 = torch.lgamma(prior) - torch.lgamma(alpha_hat)\n",
        "        term2 = (alpha_hat - prior) * torch.digamma(alpha_hat)\n",
        "        kl_comp = term1 + term2\n",
        "        kl = kl_comp.sum(dim=1)  # per example sum over K\n",
        "        KLD=kl.mean()\n",
        "        return BCE + KLD\n",
        "\n",
        "\n",
        "class DirVAETrainer:\n",
        "    \"\"\"Trainer class for Dir-VAE\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: DirVAE,\n",
        "        config: Config,\n",
        "        device: torch.device,\n",
        "        train_loader: torch.utils.data.DataLoader,\n",
        "        test_loader: torch.utils.data.DataLoader,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        # Initialize optimizer\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    def train_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_idx, (data, _) in enumerate(self.train_loader):\n",
        "            data = data.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            recon_batch, z,alpha_hat,v = self.model(data)\n",
        "            loss = self.model.loss_function(recon_batch,data, alpha_hat)\n",
        "\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if batch_idx % self.config.log_interval == 0:\n",
        "                print(\n",
        "                    f\"Train Epoch: {epoch} [{batch_idx * len(data):5d}/\"\n",
        "                    f\"{len(self.train_loader.dataset)} \"\n",
        "                    f\"({100. * batch_idx / len(self.train_loader):3.0f}%)]\"\n",
        "                    f\"\\tLoss: {loss.item() / len(data):.6f}\"\n",
        "                )\n",
        "\n",
        "        avg_loss = train_loss / len(self.train_loader.dataset)\n",
        "        print(f\"====> Epoch: {epoch} Average loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def test_epoch(self, epoch: int) -> float:\n",
        "        \"\"\"Test for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (data, _) in enumerate(self.test_loader):\n",
        "                data = data.to(self.device)\n",
        "                recon_batch,z, alpha_hat,v = self.model(data)\n",
        "                loss = self.model.loss_function(recon_batch,data, alpha_hat)\n",
        "                test_loss += loss.item()\n",
        "\n",
        "                if i == 0:\n",
        "                    n = min(data.size(0), 18)\n",
        "                    # Properly reshape for comparison\n",
        "                    comparison = torch.cat(\n",
        "                        [data[:n], recon_batch.view(data.size(0), 1, 28, 28)[:n]]\n",
        "                    )\n",
        "                    save_image(\n",
        "                        comparison.cpu(),\n",
        "                        os.path.join(self.config.output_dir, f\"recon_{epoch}.png\"),\n",
        "                        nrow=n,\n",
        "                    )\n",
        "\n",
        "        avg_loss = test_loss / len(self.test_loader.dataset)\n",
        "        print(f\"====> Test set loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n",
        "    def generate_samples(self, epoch: int, num_samples: int = 64):\n",
        "        \"\"\"Generate samples from the model\"\"\"\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Sample from latent space\n",
        "            sample = torch.randn(num_samples, self.config.category).to(self.device)\n",
        "            sample = self.model.decode(sample).cpu()\n",
        "            save_image(\n",
        "                sample.view(num_samples, 1, 28, 28),\n",
        "                os.path.join(self.config.output_dir, f\"sample_{epoch}.png\"),\n",
        "            )\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(\"Starting training...\")\n",
        "        print(f\"Configuration: {self.config}\")\n",
        "\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            train_loss = self.train_epoch(epoch)\n",
        "            test_loss = self.test_epoch(epoch)\n",
        "            self.generate_samples(epoch)\n",
        "\n",
        "\n",
        "\"\"\"Main function\"\"\"\n",
        "# Parse arguments\n",
        "parser = create_argument_parser()\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "# Create configuration\n",
        "config = Config(\n",
        "    batch_size=args.batch_size,\n",
        "    epochs=args.epochs,\n",
        "    learning_rate=args.learning_rate,\n",
        "    no_cuda=args.no_cuda,\n",
        "    seed=args.seed,\n",
        "    log_interval=args.log_interval,\n",
        "    category=args.category,\n",
        "    alpha=args.alpha,\n",
        "    data_dir=args.data_dir,\n",
        "    output_dir=args.output_dir,\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Setup device and random seeds\n",
        "    device = setup_device_and_seed(config)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader, test_loader = create_data_loaders(config)\n",
        "\n",
        "    # Create model\n",
        "    model = DirVAE(config, device).to(device)\n",
        "    print(\n",
        "        f\"Model created with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\"\n",
        "    )\n",
        "\n",
        "    # Create trainer and start training\n",
        "    trainer = DirVAETrainer(model, config, device, train_loader, test_loader)\n",
        "    trainer.train()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\", file=sys.stderr)\n",
        "    sys.exit(1)\n"
      ],
      "metadata": {
        "id": "-BQWTMx5RxP-",
        "outputId": "70fd35cf-3faa-499d-db54-d8e3b65a59f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Error during training: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1253410673.py\", line 511, in <cell line: 0>\n",
            "    device = setup_device_and_seed(config)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1253410673.py\", line 113, in setup_device_and_seed\n",
            "    torch.manual_seed(config.seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_compile.py\", line 53, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/random.py\", line 46, in manual_seed\n",
            "    torch.cuda.manual_seed_all(seed)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 131, in manual_seed_all\n",
            "    _lazy_call(cb, seed_all=True)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 341, in _lazy_call\n",
            "    callable()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\", line 129, in cb\n",
            "    default_generator.manual_seed(seed)\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1253410673.py\", line 528, in <cell line: 0>\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1253410673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;31m# Setup device and random seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_device_and_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1253410673.py\u001b[0m in \u001b[0;36msetup_device_and_seed\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Set random seeds for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1253410673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during training: {e}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}